{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        dict = pickle.load(f, encoding='latin1')\n",
    "    return dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data1= unpickle('data_batch_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Training Features:\n",
      "10000\n",
      "Size of the Testing Features:\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "X_train1 = data1['data']\n",
    "Y_train1 = data1['labels']\n",
    "print(\"Size of the Training Features:\")\n",
    "print(len(X_train1))\n",
    "print(\"Size of the Testing Features:\")\n",
    "print(len(Y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Training Features of Fold 2 : \n",
      "10000\n",
      "Size of the Training Labels of Fold 2: \n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data2= unpickle('data_batch_2')\n",
    "X_train2 = data2['data']\n",
    "Y_train2 = data2['labels']\n",
    "print(\"Size of the Training Features of Fold 2 : \")\n",
    "print(len(X_train2))\n",
    "print(\"Size of the Training Labels of Fold 2: \")\n",
    "print(len(Y_train2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Training Features of Fold 3 : \n",
      "10000\n",
      "Size of the Training Labels of Fold 3: \n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data3= unpickle('data_batch_3')\n",
    "X_train3 = data3['data']\n",
    "Y_train3 = data3['labels']\n",
    "print(\"Size of the Training Features of Fold 3 : \")\n",
    "print(len(X_train3))\n",
    "print(\"Size of the Training Labels of Fold 3: \")\n",
    "print(len(Y_train3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Training Features of Fold 4 : \n",
      "10000\n",
      "Size of the Training Labels of Fold 4: \n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data4= unpickle('data_batch_4')\n",
    "X_train4 = data4['data']\n",
    "Y_train4 = data4['labels']\n",
    "print(\"Size of the Training Features of Fold 4 : \")\n",
    "print(len(X_train4))\n",
    "print(\"Size of the Training Labels of Fold 4: \")\n",
    "print(len(Y_train4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Training Features of Fold 5 : \n",
      "10000\n",
      "Size of the Training Labels of Fold 5: \n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data5= unpickle('data_batch_5')\n",
    "X_train5 = data5['data']\n",
    "Y_train5 = data5['labels']\n",
    "print(\"Size of the Training Features of Fold 5 : \")\n",
    "print(len(X_train5))\n",
    "print(\"Size of the Training Labels of Fold 5: \")\n",
    "print(len(Y_train5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the Training Features:\n",
      "(40000, 3072)\n",
      "The dimensions of the Training Labels:\n",
      "(40000,)\n"
     ]
    }
   ],
   "source": [
    "### Training Features.\n",
    "import numpy as np\n",
    "X_train = np.append(X_train1,X_train2,axis=0)\n",
    "X_train = np.append(X_train,X_train3,axis=0)\n",
    "X_train = np.append(X_train,X_train4,axis=0)\n",
    "Y_train = np.append(Y_train1,Y_train2,axis=0)\n",
    "Y_train = np.append(Y_train,Y_train3,axis=0)\n",
    "Y_train = np.append(Y_train,Y_train4,axis=0)\n",
    "print(\"The dimensions of the Training Features:\")\n",
    "print(X_train.shape)\n",
    "\n",
    "print(\"The dimensions of the Training Labels:\")\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the Validation Features: \n",
      "(10000, 3072)\n",
      "The dimensions of the Validation Labels: \n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#Validation Features:\n",
    "X_validation = np.array(X_train5)\n",
    "Y_validation = np.array(Y_train5)\n",
    "print(\"The dimensions of the Validation Features: \")\n",
    "print(X_validation.shape)\n",
    "print(\"The dimensions of the Validation Labels: \")\n",
    "print(Y_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  43,  50, ..., 140,  84,  72],\n",
       "       [154, 126, 105, ..., 139, 142, 144]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification is Done.\n"
     ]
    }
   ],
   "source": [
    "########### Implementation of the KNN Model.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf = clf.fit(X_train[0:10],Y_train[0:10])\n",
    "print(\"Classification is Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 2 1 1 1]\n",
      "Accuracy on the Training Data set:\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "output_Predicted = clf.predict(X_train[0:10]);\n",
    "print(output_Predicted)\n",
    "accuracy_training = metrics.accuracy_score(output_Predicted,np.transpose(Y_train[0:10]))\n",
    "print(\"Accuracy on the Training Data set:\")\n",
    "print(accuracy_training* 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
